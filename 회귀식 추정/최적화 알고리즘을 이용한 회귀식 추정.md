# 최적화 알고리즘을 이용한 회귀식 추정

**1차 함수로 선형 회귀 이해하기**

---

$y = ax+b$

위 1차 함수의 기울기는 a이고 절편은 b

선형 회귀는 기울기와 절편을 찾아주는 것

기울기와 절편을 조정해가면서 각 점들을 나타내는 함수를 찾는 것이 선형 회귀

**문제 해결을 위해 데이터 준비 및 시각화**

---

사이킷런의 datasets 모듈에 있는 load_diabetes() 함수를 이용

💻 입력코드

```python
from sklearn.datasets import load_diabetes
import matplotlib.pyplot as plt

diabetes = load_diabetes() #당뇨병 데이터를 저장

plt.scatter(diabetes.data[:,2], diabetes.target) #scatter()함수로 산점도 그리기
plt.xlabel('x')
plt.ylabel('y')
plt.show()
```

💻 출력화면

![스크린샷 2022-06-17 오전 5.15.22.png](%E1%84%8E%E1%85%AC%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%92%E1%85%AA%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%E1%84%89%E1%85%B5%E1%86%A8%20%E1%84%8E%E1%85%AE%E1%84%8C%E1%85%A5%E1%86%BC%20d932c6609807433cb064f27356da4ae2/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-06-17_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_5.15.22.png)

**예측값 찾기**

---

예측값이란, 우리가 입력과 출력 데이터(x,y)를 통해 규칙(a,b)을 발견하면 모델을 만들었다고 한다.

그 모델에 대해 새로운 입력값을 넣으면 어떤 출력이 나오는데, 이 값이 모델을 통해 예측한 값

ŷ 과 w라는 문자 등장

y와 ŷ은 어떤 결과라는 점은 동일하지만 예측한 값이라는 점만 다르다.

w는 가중치를 의미하는 계수

이제 새로운 식으로 표현

$ŷ=wx+b$ 

```python
💡 훈련 데이터에 잘 맞는 w와 b를 찾는 법 💡

1. 무작위로 w와 b를 정한다.
2. x에서 샘플 하나를 선택하여 ŷ을 계산
3. ŷ과 선택한 샘플의 진짜 y를 비교
4. ŷ와 y가 더 가까워지도록 w,b를 조정하기
5. 모든 샘플을 처리할 때까지 다시 2~4 반복
```

**알고리즘 적용**

---

1. Genetic Algoritm
    
    알고리즘에 대한 설명 및 동작 원리는 [Genetic Algorithm](https://github.com/knurii/computerAlgorithm/blob/main/회귀식 추정/Genetic-Algorithm.md)
    
2. Simulated Algorithm
    
    알고리즘에 대한 설명 및 동작 원리는([simultedAlgorithm](https://github.com/knurii/computerAlgorithm/blob/main/회귀식%20추정/Simulated-Annealing.md))
    

**결과 고찰**

---
